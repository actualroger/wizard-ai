{
    "model_name": "DDQN_hybrid_2x15_2x5x5_2x16_2x64_500k_pooled",
    "seed": 0,
    "num_runs": 1,
    "device": "cpu",
    "start_round": 1,
    "end_round": 6,

    "agent_type": "DDQNAgent",
    "qnet_type": "GeneralDuelingQNet",
    "num_agents": 4,
    "pooled": true,
    "gamma": 1,

    "observation_dim": 65,
    "action_dim": 86,
    "input_header_len": 5,
    "input_full_layer_num": 2,
    "input_full_layer_dim": 16,
    "conv_layer_num": 2,
    "conv_channel_num": 5,
    "conv_output_channel_num": 1,
    "conv_kernel_size": 5,
    "value_hidden_layer_num": 2,
    "value_hidden_layer_dim": 16,
    "action_hidden_layer_num": 2,
    "action_hidden_layer_dim": 64,

    "total_training_time_step": 500000,

    "epsilon_schedule_type": "linear",
    "epsilon_start_value": 1.0,
    "epsilon_end_value": 0.01,
    "epsilon_duration": 250000,

    "buffer_type": "q_priority",
    "replay_buffer_size": 50000,
    "start_training_step": 2000,
    "buffer_error_floor": 0.01,
    "buffer_error_pow": 0.6,
    "buffer_beta_schedule_type": "none",

    "freq_update_behavior_policy": 4,
    "freq_update_target_policy": 2000,

    "optimizer": "Adam",
    "loss": "MSELoss",
    "batch_size": 32,
    "learning_rate": 1e-3
}